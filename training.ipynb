{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from model import *\n",
    "from decode import *\n",
    "from spell import *\n",
    "from wer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lipnet = LipNet(3,100,50,75,32,28)\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "lipnet.model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = Spell(path='./grid.txt')\n",
    "decoder = Decoder(greedy=False, beam_width=200, postprocessors=[labels_to_text, spell.sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('x_input.csv')\n",
    "y = pd.read_csv('y_label.csv')\n",
    "x = x.drop('Unnamed: 0',axis=1)\n",
    "y = y.drop('Unnamed: 0',axis=1)\n",
    "y['ctc_text'] += '____'\n",
    "dataset = pd.merge(x, y)\n",
    "dataset=dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dataset.loc[:0.7*len(dataset)-1]\n",
    "x_val = dataset.loc[0.7*len(dataset):0.9*len(dataset)-1]\n",
    "x_test = dataset.loc[0.9*len(dataset):]\n",
    "x_train = x_train.reset_index(drop=True)\n",
    "x_val = x_val.reset_index(drop=True)\n",
    "x_test = x_test.reset_index(drop=True)\n",
    "assert len(dataset) == len(x_train) + len(x_val) + len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {\"_\": 0, \"<s>\": 1, \"</s>\": 2, \"<unk>\": 3, \"|\": 4, \"E\": 5, \"T\": 6, \"A\": 7, \"O\": 8, \"N\": 9, \"I\": 10, \"H\": 11, \"S\": 12, \"R\": 13, \"D\": 14, \"L\": 15, \"U\": 16, \"M\": 17, \"W\": 18, \"C\": 19, \"F\": 20, \"G\": 21, \"Y\": 22, \"P\": 23, \"B\": 24, \"V\": 25, \"K\": 26, \"'\": 27, \"X\": 28, \"J\": 29, \"Q\": 30, \"Z\": 31}\n",
    "rev_tokens = {value : key for (key, value) in tokens.items()}\n",
    "extra_tokens = { 'bos_token' :\"<s>\" , 'eos_token' :\"</s>\" , 'unk_token' : \"<unk>\" , 'pad_token' : \"_\" , 'word_delimiter_token' : \"|\" }\n",
    "rev_extra_tokens = {value : key for (key, value) in extra_tokens.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(csv, start, batch_size = 16):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    input_length = np.ones((batch_size,1))*75\n",
    "    label_length = np.ones((batch_size,1))*32\n",
    "    ids = []\n",
    "    for i in range(min(batch_size,len(csv)-start)):\n",
    "        ids.append(csv['ids'][start+i])\n",
    "        x = np.load(csv['output_paths'][start+i])\n",
    "        x = np.transpose(x , (0,2,1,3))\n",
    "        y = []\n",
    "        for c in csv['ctc_text'][start+i]:\n",
    "            y.append(tokens[c])\n",
    "        y = np.array(y)\n",
    "        inputs.append(x)\n",
    "        labels.append(y)\n",
    "        \n",
    "    return [np.array(inputs),np.array(labels),input_length,label_length] , np.zeros((batch_size,)) , ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(array,ids,csv):\n",
    "    \n",
    "    y_pred = lipnet.model.predict(array)\n",
    "    pred = decoder.decode(y_pred, [75])\n",
    "    wers = []\n",
    "    for i in range(len(pred)):\n",
    "        predd = pred[i]\n",
    "        wer = wer_sentence(pred.lower(), csv[ids]['transcriptions'])\n",
    "        wers.append(wer)\n",
    "    return wers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_train = 1\n",
    "batch_size_train = 1\n",
    "start_val = 0\n",
    "batch_size_val = 1\n",
    "wer_train=[]\n",
    "wer_val=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs :  1\n",
      "Start :  1\n",
      "Epochs :  1\n",
      "Start :  1\n",
      "1/1 [==============================] - 8s 8s/step - loss: inf\n",
      "1/1 [==============================] - 8s 8s/step - loss: inf\n",
      "Epochs :  2\n",
      "Start :  2\n",
      "Epochs :  2\n",
      "Start :  2\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  3\n",
      "Start :  3\n",
      "Epochs :  3\n",
      "Start :  3\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  4\n",
      "Start :  4\n",
      "Epochs :  4\n",
      "Start :  4\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  5\n",
      "Start :  5\n",
      "Epochs :  5\n",
      "Start :  5\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  6\n",
      "Start :  6\n",
      "Epochs :  6\n",
      "Start :  6\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  7\n",
      "Start :  7\n",
      "Epochs :  7\n",
      "Start :  7\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  8\n",
      "Start :  8\n",
      "Epochs :  8\n",
      "Start :  8\n",
      "Error\n",
      "Error\n",
      "Epochs :  8\n",
      "Start :  9\n",
      "Epochs :  8\n",
      "Start :  9\n",
      "Error\n",
      "Error\n",
      "Epochs :  8\n",
      "Start :  10\n",
      "Epochs :  8\n",
      "Start :  10\n",
      "Error\n",
      "Error\n",
      "Epochs :  8\n",
      "Start :  11\n",
      "Epochs :  8\n",
      "Start :  11\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  9\n",
      "Start :  12\n",
      "Epochs :  9\n",
      "Start :  12\n",
      "Error\n",
      "Error\n",
      "Epochs :  9\n",
      "Start :  13\n",
      "Epochs :  9\n",
      "Start :  13\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  10\n",
      "Start :  14\n",
      "Epochs :  10\n",
      "Start :  14\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  11\n",
      "Start :  15\n",
      "Epochs :  11\n",
      "Start :  15\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  12\n",
      "Start :  16\n",
      "Epochs :  12\n",
      "Start :  16\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  13\n",
      "Start :  17\n",
      "Epochs :  13\n",
      "Start :  17\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  14\n",
      "Start :  18\n",
      "Epochs :  14\n",
      "Start :  18\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  15\n",
      "Start :  19\n",
      "Epochs :  15\n",
      "Start :  19\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  16\n",
      "Start :  20\n",
      "Epochs :  16\n",
      "Start :  20\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  17\n",
      "Start :  21\n",
      "Epochs :  17\n",
      "Start :  21\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  18\n",
      "Start :  22\n",
      "Epochs :  18\n",
      "Start :  22\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  19\n",
      "Start :  23\n",
      "Epochs :  19\n",
      "Start :  23\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  20\n",
      "Start :  24\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  20\n",
      "Start :  24\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  21\n",
      "Start :  25\n",
      "Epochs :  21\n",
      "Start :  25\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  22\n",
      "Start :  26\n",
      "Epochs :  22\n",
      "Start :  26\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  23\n",
      "Start :  27\n",
      "Epochs :  23\n",
      "Start :  27\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  24\n",
      "Start :  28\n",
      "Epochs :  24\n",
      "Start :  28\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  25\n",
      "Start :  29\n",
      "Epochs :  25\n",
      "Start :  29\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  26\n",
      "Start :  30\n",
      "Epochs :  26\n",
      "Start :  30\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  27\n",
      "Start :  31\n",
      "Epochs :  27\n",
      "Start :  31\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  28\n",
      "Start :  32\n",
      "Epochs :  28\n",
      "Start :  32\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  29\n",
      "Start :  33\n",
      "Epochs :  29\n",
      "Start :  33\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "Epochs :  30\n",
      "Start :  34\n",
      "Epochs :  30\n",
      "Start :  34\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n",
      "1/1 [==============================] - 2s 2s/step - loss: inf\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-584a876fb1ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m23100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mstart_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstart_train\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-0eb88193c33b>\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(csv, start, batch_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlabel_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m#x = np.transpose(x , (0,2,1,3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 440\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m                     \u001b[0mread_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_count\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"array data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                     array[i:i+read_count] = numpy.frombuffer(data, dtype=dtype,\n\u001b[0m\u001b[1;32m    728\u001b[0m                                                              count=read_count)\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-584a876fb1ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m23100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mstart_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstart_train\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-0eb88193c33b>\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(csv, start, batch_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlabel_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m#x = np.transpose(x , (0,2,1,3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 440\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m                     \u001b[0mread_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_count\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"array data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                     array[i:i+read_count] = numpy.frombuffer(data, dtype=dtype,\n\u001b[0m\u001b[1;32m    728\u001b[0m                                                              count=read_count)\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "print('Epochs : ',epochs)\n",
    "print('Start : ',start_train)\n",
    "for i in range(100):\n",
    "    \n",
    "    xt,yt,it = generator(x_train, start_train, batch_size = batch_size_train)\n",
    "    start_train += batch_size_train\n",
    "    if start_train >= len(x_train):\n",
    "        start_train = 0\n",
    "\n",
    "    xv,yv,iv = generator(x_val, start_val, batch_size = batch_size_val)\n",
    "    start_val += batch_size_val\n",
    "    if start_val >= len(x_val):\n",
    "        start_val = 0\n",
    "        \n",
    "    try:\n",
    "        h = lipnet.model.fit(xt,yt,epochs = 1)\n",
    "        epochs += 1\n",
    "        wer_train += predict(xt[0],it,x_train)\n",
    "        wer_val += predict(xv[0],iv,x_val)\n",
    "    except:\n",
    "        print('Error')\n",
    "        continue\n",
    "    print('Epochs : ',epochs)\n",
    "    print('Start : ',start_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
